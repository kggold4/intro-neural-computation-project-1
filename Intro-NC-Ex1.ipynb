{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node() -> (float, float):\n",
    "    x = random.randint(-10000, 10000)\n",
    "    y = random.randint(-10000, 10000)\n",
    "    return (x / 100, y / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(data: int):\n",
    "    return 1 if data > 1 else -1\n",
    "\n",
    "def create_data(n=1000) -> tuple:\n",
    "    data = []\n",
    "    label = []\n",
    "    for _ in range(n):\n",
    "        node = generate_node()\n",
    "        data.append(node)\n",
    "        label.append(step(node[1]))\n",
    "    return (np.array(data), np.array(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "EPOCH = 100\n",
    "\n",
    "class AdalineModel():\n",
    "    def __init__(self):\n",
    "        self.bias = 0.1\n",
    "        self.mse = 0\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        out=self.calc(X)\n",
    "        error= Y-out\n",
    "        self.weights[1:] += LEARNING_RATE * X.T.dot(error)\n",
    "            #Weight w_Update 0\n",
    "        self.weights[0] += LEARNING_RATE * error.sum()\n",
    "        self.mse += (error**2).sum()\n",
    "            \n",
    "    def fit(self, train_data: list, train_label: list):\n",
    "        #self.weights=np.random.uniform(low=0, high=1, size=train_data.shape[1])\n",
    "        rgen = np.random.RandomState(1)\n",
    "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=1 + train_data.shape[1])\n",
    "        for _ in range(EPOCH):\n",
    "            self.train(train_data, train_label)\n",
    "                \n",
    "            \n",
    "    def calc(self,X):\n",
    "        return np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "    \n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        res=np.dot(test_data, self.weights[1:]) + self.weights[0]\n",
    "        output=np.where(res>=1.0,1,-1)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def MSE(real, output):\n",
    "        return ((np.array(real) - np.array(output))**2).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(real, output):\n",
    "        count = t != np.sign(test_label)\n",
    "        return np.sum(count)/len(real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talso\\AppData\\Local\\Temp/ipykernel_22412/2084187934.py:15: RuntimeWarning: overflow encountered in square\n",
      "  self.mse += (error**2).sum()\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = create_data()\n",
    "test_data, test_label = create_data()\n",
    "        \n",
    "am = AdalineModel()\n",
    "am.fit(train_data, train_label)\n",
    "resuls = am.predict(test_data)\n",
    "# print(am.MSE(test_label, resuls))\n",
    "print(am.accuracy(test_label, resuls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADALINE's learning rules are very similar to Perceptron. Implemented below\n",
    "eta=0.1\n",
    "epoch=10\n",
    "import numpy as np\n",
    "class AdalineGD(object):\n",
    "\n",
    "    def __init__(self,  n_iter=20, random_state=1):\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        self.bias=0.5\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(1)\n",
    "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=train_data.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for _ in range(self.n_iter): #Repeat training data for the number of trainings\n",
    "            output = self.net_input(X)\n",
    "            errors = y - output\n",
    "            self.weights[:] += eta * X.T.dot(errors)\n",
    "            #Weight w_Update 0\n",
    "            self.bias += eta * errors.sum()\n",
    "            #Calculation of cost function\n",
    "            cost = (errors ** 2).sum() / 2.0\n",
    "            #Cost storage\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate total input\"\"\"\n",
    "        return np.dot(X, self.weights[:]) + self.bias #You don't have to loop with xi\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Calculate the output of the linear activation function\"\"\"\n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns the class label after one step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 1.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg=AdalineGD()\n",
    "amg.fit(np.array(train_data),np.array(train_label))\n",
    "t=amg.predict(np.array(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823\n"
     ]
    }
   ],
   "source": [
    "print(am.accuracy(t,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
